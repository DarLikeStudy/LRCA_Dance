# Listen Rhythm, Choose Movements: Decoupled Multimodal Dance Dataset for Autoregressive Dance Generation via Diffusion and Mamba Models

**Arxiv 2024**

> **å¼ ä¸‰Â¹**, **æå››Â²**, **ç‹äº”Â¹**
> 
> Â¹XXå¤§å­¦, Â²YYç ”ç©¶é™¢
> 
> \[ [Paper PDF](./paper.pdf) | [Code](https://github.com/ä½ çš„ç”¨æˆ·å/cross-modal-retrieval-cvpr24) | [Dataset](https://example.com/dataset-link) | [Project Page](https://ä½ çš„ç”¨æˆ·å.github.io/cross-modal-retrieval-cvpr24) \]

---

## ğŸ“ Abstract

æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„è·¨æ¨¡æ€æ£€ç´¢æ–¹æ³•... (è¿™é‡Œå†™ä½ çš„è®ºæ–‡æ‘˜è¦)

---

## ğŸ”¥ Highlights

- **æ ¸å¿ƒåˆ›æ–°ç‚¹ä¸€**: ç®€å•æè¿°ä½ çš„ç¬¬ä¸€ä¸ªä¸»è¦è´¡çŒ®ã€‚
- **æ ¸å¿ƒåˆ›æ–°ç‚¹äºŒ**: ç®€å•æè¿°ä½ çš„ç¬¬äºŒä¸ªä¸»è¦è´¡çŒ®ã€‚
- **SOTAæ€§èƒ½**: åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚

---

## ğŸ“Š Results

| Dataset | Metric | Ours | Previous SOTA |
| :--- | :--- | :--- | :--- |
| MSCOCO | R@1 | **85.2** | 84.1 |
| Flickr30k | R@1 | **78.9** | 77.5 |

---

## ğŸ› ï¸ Setup

æˆ‘ä»¬çš„ä»£ç åŸºäº PyTorchã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è®¾ç½®ç¯å¢ƒï¼š

```bash
git clone https://github.com/ä½ çš„ç”¨æˆ·å/cross-modal-retrieval-cvpr24.git
cd cross-modal-retrieval-cvpr24
conda create -n crossmodal python=3.8
conda activate crossmodal
pip install -r requirements.txt
```

---

## ğŸ“œ Citation

å¦‚æœæˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{zhang2024novel,
  title={A Novel Attention-based Cross-Modal Retrieval Method},
  author={Zhang, San and Li, Si and Wang, Wu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={xxxx--xxxx},
  year={2024}
}
```

---

## ğŸ“§ Contact

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·é€šè¿‡ `your.email@example.com` è”ç³»æˆ‘ä»¬ã€‚
